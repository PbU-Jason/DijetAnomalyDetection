{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import packages\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport matplotlib.pyplot as plt\nimport imageio\nimport shutil\n\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Activation, Input, LSTM, Permute, Reshape, Masking, TimeDistributed, MaxPooling1D, Flatten, Bidirectional\nfrom keras.layers.merge import *\nfrom keras.layers import Lambda\nfrom keras.layers import Dropout\nfrom keras.layers import concatenate, maximum, dot, average, add, subtract\n# from keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU, PReLU, ELU\nfrom keras.layers import Conv1D, GlobalMaxPooling1D, Conv2D, UpSampling2D, Conv2DTranspose, MaxPooling2D\nfrom keras.layers.merge import *\nfrom keras.optimizers import *\nfrom keras.regularizers import *\nfrom keras.models import load_model\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.optimizers import SGD, Adam\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.utils import shuffle\n\nfrom scipy.stats import entropy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-28T12:05:01.524309Z","iopub.execute_input":"2022-05-28T12:05:01.524968Z","iopub.status.idle":"2022-05-28T12:05:10.758008Z","shell.execute_reply.started":"2022-05-28T12:05:01.524846Z","shell.execute_reply":"2022-05-28T12:05:10.756618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install tables","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:10.760781Z","iopub.execute_input":"2022-05-28T12:05:10.762358Z","iopub.status.idle":"2022-05-28T12:05:28.194842Z","shell.execute_reply.started":"2022-05-28T12:05:10.762248Z","shell.execute_reply":"2022-05-28T12:05:28.193437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # remove previous output\n\n# shutil.rmtree('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:28.197274Z","iopub.execute_input":"2022-05-28T12:05:28.198612Z","iopub.status.idle":"2022-05-28T12:05:28.204821Z","shell.execute_reply.started":"2022-05-28T12:05:28.198547Z","shell.execute_reply":"2022-05-28T12:05:28.203719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input files's path\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:28.208138Z","iopub.execute_input":"2022-05-28T12:05:28.209364Z","iopub.status.idle":"2022-05-28T12:05:28.223181Z","shell.execute_reply.started":"2022-05-28T12:05:28.209309Z","shell.execute_reply":"2022-05-28T12:05:28.222102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load Wprime\n\npath_Wprime = '../input/phys591000-2022-final-project-iii/events_anomalydetection_DelphesPythia8_v2_Wprime_features.h5' \nWprime_jet = pd.read_hdf(path_Wprime)\n\nprint('Wprime_jet.shape: ', Wprime_jet.shape)\nprint('Features: ', Wprime_jet.columns)\n\nprint('Wprime_jet')\ndisplay(Wprime_jet)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:28.230979Z","iopub.execute_input":"2022-05-28T12:05:28.231387Z","iopub.status.idle":"2022-05-28T12:05:28.539531Z","shell.execute_reply.started":"2022-05-28T12:05:28.231353Z","shell.execute_reply":"2022-05-28T12:05:28.538541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data processing: Wprime → training features\n\npj1 = np.sqrt(Wprime_jet['pxj1']**2 + Wprime_jet['pyj1']**2 + Wprime_jet['pzj1']**2)\npTj1 = np.sqrt(Wprime_jet['pxj1']**2 + Wprime_jet['pyj1']**2)\nphij1 = np.arccos(Wprime_jet['pxj1']/pTj1)\netaj1 = np.arcsinh(Wprime_jet['pzj1']/pTj1)\nmj1 = Wprime_jet['mj1']\nE1 = np.sqrt(pj1**2 + mj1**2)\n\npj2 = np.sqrt(Wprime_jet['pxj2']**2 + Wprime_jet['pyj2']**2 + Wprime_jet['pzj2']**2)\npTj2 = np.sqrt(Wprime_jet['pxj2']**2 + Wprime_jet['pyj2']**2)\nphij2 = np.arccos(Wprime_jet['pxj2']/pTj2)\nj2_rotate = phij2 - phij1\netaj2 = np.arcsinh(Wprime_jet['pzj2']/pTj2)\nmj2 = Wprime_jet['mj2']\nE2 = np.sqrt(pj2**2 + mj2**2)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:28.540946Z","iopub.execute_input":"2022-05-28T12:05:28.541883Z","iopub.status.idle":"2022-05-28T12:05:28.590723Z","shell.execute_reply.started":"2022-05-28T12:05:28.541835Z","shell.execute_reply":"2022-05-28T12:05:28.589619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collect 7 training features\n\ntrain = pd.DataFrame({'pTj1': pTj1,\n                      'etaj1': etaj1,\n                      'mj1': mj1,\n                      'pTj2': pTj2,\n                      'phij2': j2_rotate,\n                      'etaj2': etaj2,\n                      'mj2': mj2})\n\npd.reset_option('display')\nprint('train')\ndisplay(train)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:28.592267Z","iopub.execute_input":"2022-05-28T12:05:28.592595Z","iopub.status.idle":"2022-05-28T12:05:28.616956Z","shell.execute_reply.started":"2022-05-28T12:05:28.592566Z","shell.execute_reply":"2022-05-28T12:05:28.615937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rescale training features to [-1,1]\n\nTrain = train.values\nscaler_Train = MinMaxScaler((-1, 1))\nscaler_Train.fit(Train)\nTrain_rescaled = scaler_Train.transform(Train)\n\nprint('Train_rescaled.shape:', Train_rescaled.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:28.620181Z","iopub.execute_input":"2022-05-28T12:05:28.620551Z","iopub.status.idle":"2022-05-28T12:05:28.634005Z","shell.execute_reply.started":"2022-05-28T12:05:28.620518Z","shell.execute_reply":"2022-05-28T12:05:28.633168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generator of GAN\n\ndef make_generator_cnn(GAN_noise_size, GAN_output_size):\n    # Build Generative model ...\n\n    G_input = Input(shape=(GAN_noise_size,))\n\n    G = Dense(128, kernel_initializer='glorot_uniform')(G_input)\n    #G = Dropout(0.2)(G)\n    G = LeakyReLU(alpha=0.2)(G)\n    #G = Activation(\"relu\")(G)\n    G = BatchNormalization()(G)\n\n    G = Reshape([8, 8, 2])(G)  # default: channel last\n\n    G = Conv2DTranspose(32, kernel_size=2, strides=1, padding='same')(G)\n    #G = Activation(\"relu\")(G)\n    G = LeakyReLU(alpha=0.2)(G)\n    G = BatchNormalization()(G)\n\n    G = Conv2DTranspose(16, kernel_size=3, strides=1, padding='same')(G)\n    G = LeakyReLU(alpha=0.2)(G)\n    G = BatchNormalization()(G)\n\n    G = Flatten()(G)\n\n    G_output = Dense(GAN_output_size)(G)\n    G_output = Activation('tanh')(G_output)\n    #G_output = Dense(GAN_output_size)(G)\n    #G_output = LeakyReLU(0.2)(G_output)\n    generator = Model(G_input, G_output)\n\n    return generator","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:28.635209Z","iopub.execute_input":"2022-05-28T12:05:28.636151Z","iopub.status.idle":"2022-05-28T12:05:28.646753Z","shell.execute_reply.started":"2022-05-28T12:05:28.636076Z","shell.execute_reply":"2022-05-28T12:05:28.645466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# discriminator of GAN\n\ndef make_discriminator_cnn(GAN_output_size):\n    # Build Discriminative model ...\n    # print \"DEBUG: discriminator: input features:\", GAN_output_size\n\n    D_input = Input(shape=(GAN_output_size,))\n\n    D = Dense(128)(D_input)\n    D = Reshape((8, 8, 2))(D)\n\n    D = Conv2D(64, kernel_size=3, strides=1, padding='same')(D)\n    D = LeakyReLU(alpha=0.2)(D)\n\n    D = Conv2D(32, kernel_size=3, strides=1, padding='same')(D)\n    #D = BatchNormalization()(D)\n    D = LeakyReLU(alpha=0.2)(D)\n\n    D = Conv2D(16, kernel_size=3, strides=1, padding='same')(D)\n    #D = BatchNormalization()(D)\n    D = LeakyReLU(alpha=0.2)(D)\n\n    D = Flatten()(D)\n    #D = BatchNormalization()(D)\n    D = LeakyReLU(alpha=0.2)(D)\n\n    D = Dropout(0.2)(D)\n\n    D_output = Dense(1, activation='sigmoid')(D)\n    #D_output = Dense(1)(D)\n\n    discriminator = Model(D_input, D_output)\n    \n    return discriminator","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:28.648063Z","iopub.execute_input":"2022-05-28T12:05:28.648702Z","iopub.status.idle":"2022-05-28T12:05:28.665545Z","shell.execute_reply.started":"2022-05-28T12:05:28.64866Z","shell.execute_reply":"2022-05-28T12:05:28.66472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build up GAN models\n\ntf.keras.backend.clear_session()\n\nGAN_noise_size = 128\nn_features = Train_rescaled.shape[1]\n\n# d_optimizer = Adam(learning_rate=0.00001, beta_1=0.5, beta_2=0.9)\n# g_optimizer = Adam(learning_rate=0.00001, beta_1=0.5, beta_2=0.9)\n\nd_optimizer = SGD(0.01)\ng_optimizer = SGD(0.01)\n\ngenerator = make_generator_cnn(GAN_noise_size, n_features)\ngenerator._name = \"Generator\"\ngenerator.compile(loss='mean_squared_error', optimizer=g_optimizer)\ngenerator.summary()\n\ndiscriminator = make_discriminator_cnn(n_features)\ndiscriminator._name = \"Discriminator\"\ndiscriminator.compile(loss='binary_crossentropy', optimizer=d_optimizer, metrics=['accuracy'])\ndiscriminator.summary()\n\ndiscriminator.trainable = False\nGAN_input = Input(shape=(GAN_noise_size,))\nGAN_latent = generator(GAN_input)\nGAN_output = discriminator(GAN_latent)\nGAN = Model(GAN_input, GAN_output)\nGAN._name = \"GAN\"\nGAN.compile(loss='binary_crossentropy', optimizer=g_optimizer)\nGAN.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:28.666626Z","iopub.execute_input":"2022-05-28T12:05:28.666944Z","iopub.status.idle":"2022-05-28T12:05:29.068971Z","shell.execute_reply.started":"2022-05-28T12:05:28.666916Z","shell.execute_reply":"2022-05-28T12:05:29.067786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build up training loop\n\ndef train_loop(epochs, batch_size):\n    \n    Train_rescaled_real_label = np.ones((batch_size, 1))\n    Train_rescaled_fake_label = np.zeros((batch_size, 1))\n    \n    saved_epoch_list = []\n    saved_fakedata_list = []\n    for epoch in range(epochs):\n        \n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n\n        Train_rescaled_idx = np.random.randint(0, Train_rescaled.shape[0], size=batch_size)\n        Train_rescaled_real = Train_rescaled[Train_rescaled_idx, :]\n\n        # generate fake events\n        Train_rescaled_noise = np.random.uniform(0, 1, size=[batch_size, GAN_noise_size])\n        Train_rescaled_fake = generator.predict(Train_rescaled_noise)\n\n        discriminator.trainable = True\n\n        d_loss_r, d_acc_r = discriminator.train_on_batch(Train_rescaled_real, Train_rescaled_real_label)\n        d_loss_f, d_acc_f = discriminator.train_on_batch(Train_rescaled_fake, Train_rescaled_fake_label)\n        d_loss = 0.5 * np.add(d_loss_r, d_loss_f)\n        d_acc = 0.5 * np.add(d_acc_r, d_acc_f)\n\n        history['d_loss'].append(d_loss)\n        history['d_loss_r'].append(d_loss_r)\n        history['d_loss_f'].append(d_loss_f)\n        history['d_acc'].append(d_acc)\n        history['d_acc_r'].append(d_acc_r)\n        history['d_acc_f'].append(d_acc_f)\n\n        # ---------------------\n        #  Train Generator\n        # ---------------------\n\n        # we want discriminator to mistake images as real\n        discriminator.trainable = False\n\n        g_loss = GAN.train_on_batch(Train_rescaled_noise, Train_rescaled_real_label)\n        history['g_loss'].append(g_loss)\n\n        if epoch % 10000 == 0:\n            print('Epoch: %d, discriminator(loss: %.3f, acc.: %.2f%%), generator(loss: %.3f)' % (epoch, d_loss, d_acc*100., g_loss))\n            saved_epoch_list.append(epoch)\n            saved_fakedata_list.append(scaler_Train.inverse_transform(generator(tf.random.uniform((10000, 128)), training=False)))\n            \n        epoch += 1\n    \n    np.savez('GAN_saved_fakedata_%d.npz' %(epoch), epoch=saved_epoch_list, fakedata=saved_fakedata_list)\n    generator.save('GAN_generator_%d.h5' %(epoch))\n    discriminator.save('GAN_discriminator_%d.h5' %(epoch))\n    GAN.save('GAN_%d.h5' %(epoch))\n\n    return","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:29.070959Z","iopub.execute_input":"2022-05-28T12:05:29.071616Z","iopub.status.idle":"2022-05-28T12:05:29.086981Z","shell.execute_reply.started":"2022-05-28T12:05:29.071578Z","shell.execute_reply":"2022-05-28T12:05:29.08594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train GAN models & saved useful outputs\n\nhistory = {'g_loss': [],\n           'd_loss': [], 'd_loss_r': [], 'd_loss_f': [],\n           'd_acc': [], 'd_acc_r': [], 'd_acc_f': []}\n\nepochs = 250000\nbatch_size = 100\ntrain_loop(epochs, batch_size)\n\nwith open('GAN_history_%d.pickle' %(epochs), 'wb') as f:\n    pickle.dump(history, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:05:29.088402Z","iopub.execute_input":"2022-05-28T12:05:29.088953Z","iopub.status.idle":"2022-05-28T12:08:00.57839Z","shell.execute_reply.started":"2022-05-28T12:05:29.088908Z","shell.execute_reply":"2022-05-28T12:08:00.577142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot final result & check K-L divergence\n\nrealdata= shuffle(Wprime_jet['mj1'])\nfakedata = scaler_Train.inverse_transform(generator(tf.random.uniform((10000, 128)), training=False))\n\nrealhist, realbins = np.histogram(realdata[:10000], bins = 25, range = (10, 600), density=1)\nfakehist, fakebins = np.histogram(fakedata[:,2], bins = 25, range = (10, 600), density=1)\n\nfig, axis = plt.subplots(1, 1, figsize=(8,8))\nplt.title('epoch = '+str(epochs), fontsize=20)\nplt.ylim([0,0.012])\nplt.step(fakebins[:-1], fakehist, label = 'GAN')\nplt.step(realbins[:-1], realhist, label = 'Pythia8 Signal')\nplt.xlabel('$m_{J_1}$', fontsize=20)\nplt.legend(loc='upper right', fontsize=20)\nfig.savefig('epoch_final.png')\nplt.show()\n\ndef KL_divergent(p,q):\n    return entropy(p,q)\n\nprint(\"KL Divergence D_KL(real||real): {:.3f}\".format(KL_divergent(realhist[:], realhist[:])))\nprint(\"KL Divergence D_KL(fake||real): {:.3f}\".format(KL_divergent(fakehist[:], realhist[:])))\nprint(\"KL Divergence D_KL(flat||real): {:.3f}\".format(KL_divergent(np.full(len(realhist), 1/len(realhist)), realhist[:])))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:00.580351Z","iopub.execute_input":"2022-05-28T12:08:00.581196Z","iopub.status.idle":"2022-05-28T12:08:01.409501Z","shell.execute_reply.started":"2022-05-28T12:08:00.581113Z","shell.execute_reply":"2022-05-28T12:08:01.408465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot loss function & accuracy\n\nplt.figure(figsize=(7,5), dpi=150)\nplt.title('g_loss and d_loss')\nplt.plot(history['g_loss'], label='g_loss')\nplt.plot(history['d_loss'], label='d_loss')\nplt.ylabel('loss function')\nplt.xlabel('epoch')\nplt.legend()\nplt.savefig('loss.png')\nplt.show()\n\nplt.figure(figsize=(7,5), dpi=150)\nplt.title('d_acc')\nplt.plot(history['d_acc'])\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.savefig('accuracy.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:01.411014Z","iopub.execute_input":"2022-05-28T12:08:01.411406Z","iopub.status.idle":"2022-05-28T12:08:02.158176Z","shell.execute_reply.started":"2022-05-28T12:08:01.411371Z","shell.execute_reply":"2022-05-28T12:08:02.157124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot .gif of epochs evolution\n\nsaved_fakedata = np.load('GAN_saved_fakedata_%d.npz' %(epochs))\n\nprint('files: ', saved_fakedata.files)\nprint('fakedata.shape: ', saved_fakedata['fakedata'].shape)\n\nimages = []\nfor i in range(saved_fakedata['fakedata'].shape[0]):\n    \n    fakedata_old = saved_fakedata['fakedata'][i]\n    fakehist_old, fakebins_old = np.histogram(fakedata_old[:,2], bins = 25, range = (10, 600), density=1)\n    \n    fig, axis = plt.subplots(1, 1, figsize=(8,8), dpi=150)\n    plt.step(fakebins_old[:-1], fakehist_old, label = 'GAN')\n    plt.step(realbins[:-1], realhist, label = \"Pythia8 Signal\")\n    plt.title('epoch = '+str(i*10000), fontsize=20)\n    plt.ylim([0,0.012])\n    plt.xlabel('$m_{J_1}$', fontsize=20)\n    plt.legend(loc='upper right', fontsize=20)\n    plt.savefig('epoch_'+str(i)+'.png')\n    plt.close()\n\n    images.append(imageio.imread('epoch_'+str(i)+'.png'))\n\nimageio.mimsave('fakedata.gif', images, fps=1.3)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:02.159798Z","iopub.execute_input":"2022-05-28T12:08:02.160586Z","iopub.status.idle":"2022-05-28T12:08:06.751096Z","shell.execute_reply.started":"2022-05-28T12:08:02.160546Z","shell.execute_reply":"2022-05-28T12:08:06.750046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load test data\n\npath_test_data = '../input/phys591000-2022-final-project-iii/test_sample_for_discriminator.npz'\ntest_data = np.load(path_test_data)\n\nprint('test_data.files: ', test_data.files)\nprint('test_sample.shape: ', test_data['test_sample'].shape)\n\ntest = pd.DataFrame(test_data['test_sample'])\ntest.columns = ['pxj1', 'pyj1', 'pzj1', 'mj1', 'pxj2', 'pyj2', 'pzj2', 'mj2']\n\npd.reset_option('display')\nprint('test')\ndisplay(test)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:06.752604Z","iopub.execute_input":"2022-05-28T12:08:06.75312Z","iopub.status.idle":"2022-05-28T12:08:06.793613Z","shell.execute_reply.started":"2022-05-28T12:08:06.75307Z","shell.execute_reply":"2022-05-28T12:08:06.792543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data processing: test data → testing features\n\ntest_pj1 = np.sqrt(test['pxj1']**2 + test['pyj1']**2 + test['pzj1']**2)\ntest_pTj1 = np.sqrt(test['pxj1']**2 + test['pyj1']**2)\ntest_phij1 = np.arccos(test['pxj1']/test_pTj1)\ntest_etaj1 = np.arcsinh(test['pzj1']/test_pTj1)\ntest_mj1 = test['mj1']\ntest_E1 = np.sqrt(test_pj1**2 + test_mj1**2)\n\ntest_pj2 = np.sqrt(test['pxj2']**2 + test['pyj2']**2 + test['pzj2']**2)\ntest_pTj2 = np.sqrt(test['pxj2']**2 + test['pyj2']**2)\ntest_phij2 = np.arccos(test['pxj2']/test_pTj2)\ntest_j2_rotate = test_phij2 - test_phij1\ntest_etaj2 = np.arcsinh(test['pzj2']/test_pTj2)\ntest_mj2 = test['mj2']\ntest_E2 = np.sqrt(test_pj2**2 + test_mj2**2)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:06.795504Z","iopub.execute_input":"2022-05-28T12:08:06.796406Z","iopub.status.idle":"2022-05-28T12:08:06.817889Z","shell.execute_reply.started":"2022-05-28T12:08:06.796352Z","shell.execute_reply":"2022-05-28T12:08:06.816904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collect 7 testing features\n\ntest_fit = pd.DataFrame({'pTj1': test_pTj1,\n                         'etaj1': test_etaj1,\n                         'mj1': test_mj1,\n                         'pTj2': test_pTj2,\n                         'phij2': test_j2_rotate,\n                         'etaj2': test_etaj2,\n                         'mj2': test_mj2})\n\npd.reset_option('display')\nprint('test_fit')\ndisplay(test_fit)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:06.819961Z","iopub.execute_input":"2022-05-28T12:08:06.820853Z","iopub.status.idle":"2022-05-28T12:08:06.848497Z","shell.execute_reply.started":"2022-05-28T12:08:06.820799Z","shell.execute_reply":"2022-05-28T12:08:06.846966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rescale testing features to [-1,1]\n\nTest = test_fit.values\nscaler_Test = MinMaxScaler((-1, 1))\nscaler_Test.fit(Test)\nTest_rescaled = scaler_Test.transform(Test)\n\nprint('Test_rescaled.shape:', Test_rescaled.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:06.850969Z","iopub.execute_input":"2022-05-28T12:08:06.85239Z","iopub.status.idle":"2022-05-28T12:08:06.86193Z","shell.execute_reply.started":"2022-05-28T12:08:06.852332Z","shell.execute_reply":"2022-05-28T12:08:06.860859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict test data → result\n\nresult = discriminator.predict(Test_rescaled)\nprint('result.shape:', result.shape)\n\nprint('max of result:', np.max(result))\nprint('median of result:', np.median(result))\nprint('min of result:', np.min(result))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:06.863842Z","iopub.execute_input":"2022-05-28T12:08:06.864409Z","iopub.status.idle":"2022-05-28T12:08:07.447097Z","shell.execute_reply.started":"2022-05-28T12:08:06.86436Z","shell.execute_reply":"2022-05-28T12:08:07.446133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rescale result to [0,1]\n\nscaler_result = MinMaxScaler((0, 1))\nscaler_result.fit(result)\nresult_rescaled = scaler_result.transform(result)\n\nprint('result_rescaled.shape:', result_rescaled.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:07.449177Z","iopub.execute_input":"2022-05-28T12:08:07.4498Z","iopub.status.idle":"2022-05-28T12:08:07.457848Z","shell.execute_reply.started":"2022-05-28T12:08:07.449759Z","shell.execute_reply":"2022-05-28T12:08:07.456588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distribution of rescaled result\n\nresult_rescaled_hist, result_rescaled_bins = np.histogram(result_rescaled, bins = 40, range = (0, 1), density=1)\n\nfig, axis = plt.subplots(1, 1, figsize=(8,8))\nplt.step(result_rescaled_bins[:-1], result_rescaled_hist, label = \"Prediction\")\nplt.show()\n\nprint(np.max(result_rescaled))\nprint(np.median(result_rescaled))\nprint(np.min(result_rescaled))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:07.459169Z","iopub.execute_input":"2022-05-28T12:08:07.459531Z","iopub.status.idle":"2022-05-28T12:08:07.658345Z","shell.execute_reply.started":"2022-05-28T12:08:07.459498Z","shell.execute_reply":"2022-05-28T12:08:07.657293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load submission template\n\nsubmission_template = pd.read_csv('../input/phys591000-2022-final-project-iii/submission_template_randomguess.csv')\n\npd.reset_option('display')\nprint('submission_template')\ndisplay(submission_template)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:07.660007Z","iopub.execute_input":"2022-05-28T12:08:07.660956Z","iopub.status.idle":"2022-05-28T12:08:07.687474Z","shell.execute_reply.started":"2022-05-28T12:08:07.660914Z","shell.execute_reply":"2022-05-28T12:08:07.686491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save submission prediciton\n\nsubmission = submission_template.copy()\n\nsplit_level = np.median(result_rescaled)\nfor i in range(result_rescaled.shape[0]):\n    if result_rescaled[i] <= split_level:\n        final_label = 0\n    else:\n        final_label = 1\n    submission['prediction'][i] = final_label\n    \npd.reset_option('display')\nprint('submission')\ndisplay(submission)\n\nsubmission.to_csv('submission.csv', index=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:07.688903Z","iopub.execute_input":"2022-05-28T12:08:07.689349Z","iopub.status.idle":"2022-05-28T12:08:07.954922Z","shell.execute_reply.started":"2022-05-28T12:08:07.689313Z","shell.execute_reply":"2022-05-28T12:08:07.953831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check submission prediciton\n\ncount = 0\nfor i in submission['prediction']:\n    if i == 1:\n        count += 1\n        \nprint('predict to real:', count)\nprint('predict to fake:', result_rescaled.shape[0] - count)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T12:08:07.958762Z","iopub.execute_input":"2022-05-28T12:08:07.959175Z","iopub.status.idle":"2022-05-28T12:08:07.967885Z","shell.execute_reply.started":"2022-05-28T12:08:07.959139Z","shell.execute_reply":"2022-05-28T12:08:07.966621Z"},"trusted":true},"execution_count":null,"outputs":[]}]}