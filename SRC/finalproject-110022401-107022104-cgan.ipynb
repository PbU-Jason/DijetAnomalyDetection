{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import packages\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport matplotlib.pyplot as plt\nimport imageio\nimport shutil\n\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Activation, Input, LSTM, Permute, Reshape, Masking, TimeDistributed, MaxPooling1D, Flatten, Bidirectional\nfrom keras.layers.merge import *\nfrom keras.layers import Lambda\nfrom keras.layers import Dropout\nfrom keras.layers import concatenate, maximum, dot, average, add, subtract\n# from keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU, PReLU, ELU\nfrom keras.layers import Conv1D, GlobalMaxPooling1D, Conv2D, UpSampling2D, Conv2DTranspose, MaxPooling2D\nfrom keras.layers.merge import *\nfrom keras.optimizers import *\nfrom keras.regularizers import *\nfrom keras.models import load_model\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.optimizers import SGD, Adam\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.utils import shuffle\n\nfrom scipy.stats import entropy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-28T09:52:11.348756Z","iopub.execute_input":"2022-05-28T09:52:11.349289Z","iopub.status.idle":"2022-05-28T09:52:11.359353Z","shell.execute_reply.started":"2022-05-28T09:52:11.349258Z","shell.execute_reply":"2022-05-28T09:52:11.358487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install tables","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:11.416344Z","iopub.execute_input":"2022-05-28T09:52:11.417314Z","iopub.status.idle":"2022-05-28T09:52:22.400985Z","shell.execute_reply.started":"2022-05-28T09:52:11.417279Z","shell.execute_reply":"2022-05-28T09:52:22.399712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # remove previous output\n\n# shutil.rmtree('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:57.214608Z","iopub.execute_input":"2022-05-28T09:52:57.214997Z","iopub.status.idle":"2022-05-28T09:52:57.243274Z","shell.execute_reply.started":"2022-05-28T09:52:57.214967Z","shell.execute_reply":"2022-05-28T09:52:57.241976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input files's path\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.448082Z","iopub.status.idle":"2022-05-28T09:52:22.448589Z","shell.execute_reply.started":"2022-05-28T09:52:22.448345Z","shell.execute_reply":"2022-05-28T09:52:22.448365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load Wprime\n\npath_Wprime = '../input/phys591000-2022-final-project-iii/events_anomalydetection_DelphesPythia8_v2_Wprime_features.h5' \nWprime_jet = pd.read_hdf(path_Wprime)\n\nprint('Wprime_jet.shape: ', Wprime_jet.shape)\nprint('Features: ', Wprime_jet.columns)\n\nprint('Wprime_jet')\ndisplay(Wprime_jet)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.449939Z","iopub.status.idle":"2022-05-28T09:52:22.450366Z","shell.execute_reply.started":"2022-05-28T09:52:22.450178Z","shell.execute_reply":"2022-05-28T09:52:22.450197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data processing: Wprime → training features + conditional label\n\npj1 = np.sqrt(Wprime_jet['pxj1']**2 + Wprime_jet['pyj1']**2 + Wprime_jet['pzj1']**2)\npTj1 = np.sqrt(Wprime_jet['pxj1']**2 + Wprime_jet['pyj1']**2)\nphij1 = np.arccos(Wprime_jet['pxj1']/pTj1)\netaj1 = np.arcsinh(Wprime_jet['pzj1']/pTj1)\nmj1 = Wprime_jet['mj1']\nE1 = np.sqrt(pj1**2 + mj1**2)\n\npj2 = np.sqrt(Wprime_jet['pxj2']**2 + Wprime_jet['pyj2']**2 + Wprime_jet['pzj2']**2)\npTj2 = np.sqrt(Wprime_jet['pxj2']**2 + Wprime_jet['pyj2']**2)\nphij2 = np.arccos(Wprime_jet['pxj2']/pTj2)\nj2_rotate = phij2 - phij1\netaj2 = np.arcsinh(Wprime_jet['pzj2']/pTj2)\nmj2 = Wprime_jet['mj2']\nE2 = np.sqrt(pj2**2 + mj2**2)\n\nmjj = np.sqrt((E1+E2)**2 - ((Wprime_jet['pxj1']+Wprime_jet['pxj2'])**2 + (Wprime_jet['pyj1']+Wprime_jet['pyj2'])**2 + (Wprime_jet['pzj1']+Wprime_jet['pzj2'])**2))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.451562Z","iopub.status.idle":"2022-05-28T09:52:22.451912Z","shell.execute_reply.started":"2022-05-28T09:52:22.451747Z","shell.execute_reply":"2022-05-28T09:52:22.451764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collect 7 training features\n\ntrain = pd.DataFrame({'pTj1': pTj1,\n                      'etaj1': etaj1,\n                      'mj1': mj1,\n                      'pTj2': pTj2,\n                      'phij2': j2_rotate,\n                      'etaj2': etaj2,\n                      'mj2': mj2})\n\npd.reset_option('display')\nprint('train')\ndisplay(train)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.453626Z","iopub.status.idle":"2022-05-28T09:52:22.454696Z","shell.execute_reply.started":"2022-05-28T09:52:22.454479Z","shell.execute_reply":"2022-05-28T09:52:22.454505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rescale training features to [-1,1]\n\nTrain = train.values\nscaler_Train = MinMaxScaler((-1, 1))\nscaler_Train.fit(Train)\nTrain_rescaled = scaler_Train.transform(Train)\n\nprint('Train_rescaled.shape:', Train_rescaled.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.456087Z","iopub.status.idle":"2022-05-28T09:52:22.456496Z","shell.execute_reply.started":"2022-05-28T09:52:22.456319Z","shell.execute_reply":"2022-05-28T09:52:22.456338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collect 1 training conditional label\n\ncondition_Train = pd.DataFrame({'mjj': mjj})\n\npd.reset_option('display')\nprint('condition_Train')\ndisplay(condition_Train)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.45786Z","iopub.status.idle":"2022-05-28T09:52:22.45834Z","shell.execute_reply.started":"2022-05-28T09:52:22.458171Z","shell.execute_reply":"2022-05-28T09:52:22.458191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rescale training conditional label to [0,1]\n\nCondition_Train = condition_Train.values\nscaler_Condition_Train = MinMaxScaler((0, 1))\nscaler_Condition_Train.fit(Condition_Train)\nCondition_Train_rescaled = scaler_Condition_Train.transform(Condition_Train)\n\nprint('Condition_Train_rescaled.shape:', Condition_Train_rescaled.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.459189Z","iopub.status.idle":"2022-05-28T09:52:22.459639Z","shell.execute_reply.started":"2022-05-28T09:52:22.459476Z","shell.execute_reply":"2022-05-28T09:52:22.459494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generator of cGAN\n\ndef make_generator_cnn(GAN_noise_size, GAN_output_size):\n    # Build Generative model ...\n\n    G_input = Input(shape=(GAN_noise_size,))\n    G_con_label = Input(shape=(1,))\n    \n    G_merge = Concatenate()([G_input, G_con_label])\n\n    G = Dense(128, kernel_initializer='glorot_uniform')(G_merge)\n    #G = Dropout(0.2)(G)\n    G = LeakyReLU(alpha=0.2)(G)\n    #G = Activation(\"relu\")(G)\n    G = BatchNormalization()(G)\n\n    G = Reshape([8, 8, 2])(G)  # default: channel last\n\n    G = Conv2DTranspose(32, kernel_size=2, strides=1, padding='same')(G)\n    #G = Activation(\"relu\")(G)\n    G = LeakyReLU(alpha=0.2)(G)\n    G = BatchNormalization()(G)\n\n    G = Conv2DTranspose(16, kernel_size=3, strides=1, padding='same')(G)\n    G = LeakyReLU(alpha=0.2)(G)\n    G = BatchNormalization()(G)\n\n    G = Flatten()(G)\n\n    G_output = Dense(GAN_output_size)(G)\n    G_output = Activation('tanh')(G_output)\n    #G_output = Dense(GAN_output_size)(G)\n    #G_output = LeakyReLU(0.2)(G_output)\n    generator = Model([G_input, G_con_label], G_output)\n\n    return generator","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.460408Z","iopub.status.idle":"2022-05-28T09:52:22.461191Z","shell.execute_reply.started":"2022-05-28T09:52:22.460955Z","shell.execute_reply":"2022-05-28T09:52:22.460979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# discriminator of cGAN\n\ndef make_discriminator_cnn(GAN_output_size):\n    # Build Discriminative model ...\n    # print \"DEBUG: discriminator: input features:\", GAN_output_size\n\n    D_input = Input(shape=(GAN_output_size,))\n    D_con_label = Input(shape=(1,))\n    \n    D_merge = Concatenate()([D_input, D_con_label])\n\n    D = Dense(128)(D_merge)\n    D = Reshape((8, 8, 2))(D)\n\n    D = Conv2D(64, kernel_size=3, strides=1, padding='same')(D)\n    D = LeakyReLU(alpha=0.2)(D)\n\n    D = Conv2D(32, kernel_size=3, strides=1, padding='same')(D)\n    #D = BatchNormalization()(D)\n    D = LeakyReLU(alpha=0.2)(D)\n\n    D = Conv2D(16, kernel_size=3, strides=1, padding='same')(D)\n    #D = BatchNormalization()(D)\n    D = LeakyReLU(alpha=0.2)(D)\n\n    D = Flatten()(D)\n    #D = BatchNormalization()(D)\n    D = LeakyReLU(alpha=0.2)(D)\n\n    D = Dropout(0.2)(D)\n\n    D_output = Dense(1, activation='sigmoid')(D)\n    #D_output = Dense(1)(D)\n\n    discriminator = Model([D_input, D_con_label], D_output)\n    \n    return discriminator","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.462433Z","iopub.status.idle":"2022-05-28T09:52:22.462769Z","shell.execute_reply.started":"2022-05-28T09:52:22.462608Z","shell.execute_reply":"2022-05-28T09:52:22.462624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build up cGAN models\n\ntf.keras.backend.clear_session()\n\nGAN_noise_size = 128\nn_features = Train_rescaled.shape[1]\n\nd_optimizer = Adam(learning_rate=0.00001, beta_1=0.5, beta_2=0.9)\ng_optimizer = Adam(learning_rate=0.00001, beta_1=0.5, beta_2=0.9)\n\ngenerator = make_generator_cnn(GAN_noise_size, n_features)\ngenerator._name = \"cGAN_Generator\"\ngenerator.compile(loss='mean_squared_error', optimizer=g_optimizer)\ngenerator.summary()\n\ndiscriminator = make_discriminator_cnn(n_features)\ndiscriminator._name = \"cGAN_Discriminator\"\ndiscriminator.compile(loss='binary_crossentropy', optimizer=d_optimizer, metrics=['accuracy'])\ndiscriminator.summary()\n\ndiscriminator.trainable = False\nGAN_input = Input(shape=(GAN_noise_size,))\nGAN_con_label = Input(shape=(1,))\nGAN_latent = generator([GAN_input, GAN_con_label])\nGAN_output = discriminator([GAN_latent, GAN_con_label])\nGAN = Model([GAN_input, GAN_con_label], GAN_output)\nGAN._name = \"cGAN\"\nGAN.compile(loss='binary_crossentropy', optimizer=g_optimizer)\nGAN.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.463719Z","iopub.status.idle":"2022-05-28T09:52:22.464069Z","shell.execute_reply.started":"2022-05-28T09:52:22.463899Z","shell.execute_reply":"2022-05-28T09:52:22.463916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build up training loop\n\ndef train_loop(epochs, batch_size):\n    \n    Train_rescaled_real_label = np.ones((batch_size, 1))\n    Train_rescaled_fake_label = np.zeros((batch_size, 1))\n    \n    saved_epoch_list = []\n    saved_fakedata_list = []\n    for epoch in range(epochs):\n        \n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n\n        Train_rescaled_idx = np.random.randint(0, Train_rescaled.shape[0], size=batch_size)\n        Train_rescaled_real = Train_rescaled[Train_rescaled_idx, :]\n        Condition_Train_rescaled_real = Condition_Train_rescaled[Train_rescaled_idx, :]\n\n        # generate fake events\n        Train_rescaled_noise = np.random.uniform(0, 1, size=[batch_size, GAN_noise_size])\n        Train_rescaled_fake = generator.predict([Train_rescaled_noise, Condition_Train_rescaled_real])\n\n        discriminator.trainable = True\n\n        d_loss_r, d_acc_r = discriminator.train_on_batch([Train_rescaled_real, Condition_Train_rescaled_real], Train_rescaled_real_label)\n        d_loss_f, d_acc_f = discriminator.train_on_batch([Train_rescaled_fake, Condition_Train_rescaled_real], Train_rescaled_fake_label)\n        d_loss = 0.5 * np.add(d_loss_r, d_loss_f)\n        d_acc = 0.5 * np.add(d_acc_r, d_acc_f)\n\n        history['d_loss'].append(d_loss)\n        history['d_loss_r'].append(d_loss_r)\n        history['d_loss_f'].append(d_loss_f)\n        history['d_acc'].append(d_acc)\n        history['d_acc_r'].append(d_acc_r)\n        history['d_acc_f'].append(d_acc_f)\n\n        # ---------------------\n        #  Train Generator\n        # ---------------------\n\n        # we want discriminator to mistake images as real\n        discriminator.trainable = False\n\n        g_loss = GAN.train_on_batch([Train_rescaled_noise, Condition_Train_rescaled_real], Train_rescaled_real_label)\n        history['g_loss'].append(g_loss)\n\n        if epoch % 10000 == 0:\n            print('Epoch: %d, discriminator(loss: %.3f, acc.: %.2f%%), generator(loss: %.3f)' % (epoch, d_loss, d_acc*100., g_loss))\n            saved_epoch_list.append(epoch)\n            saved_fakedata_list.append(scaler_Train.inverse_transform(generator([tf.random.uniform((10000, 128)), shuffle(Condition_Train_rescaled)[:10000]], training=False)))\n            \n        epoch += 1\n    \n    np.savez('cGAN_saved_fakedata_%d.npz' %(epoch), epoch=saved_epoch_list, fakedata=saved_fakedata_list)\n    generator.save('cGAN_generator_%d.h5' %(epoch))\n    discriminator.save('cGAN_discriminator_%d.h5' %(epoch))\n    GAN.save('cGAN_%d.h5' %(epoch))\n\n    return","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.465324Z","iopub.status.idle":"2022-05-28T09:52:22.46567Z","shell.execute_reply.started":"2022-05-28T09:52:22.465504Z","shell.execute_reply":"2022-05-28T09:52:22.465519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train cGAN models & saved useful outputs\n\nhistory = {'g_loss': [],\n           'd_loss': [], 'd_loss_r': [], 'd_loss_f': [],\n           'd_acc': [], 'd_acc_r': [], 'd_acc_f': []}\n\nepochs = 250000\nbatch_size = 100\ntrain_loop(epochs, batch_size)\n\nwith open('cGAN_history_%d.pickle' %(epochs), 'wb') as f:\n    pickle.dump(history, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.468128Z","iopub.status.idle":"2022-05-28T09:52:22.468536Z","shell.execute_reply.started":"2022-05-28T09:52:22.468346Z","shell.execute_reply":"2022-05-28T09:52:22.468364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot final result & check K-L divergence\n\nrealdata, realcondition = shuffle(Wprime_jet['mj1'], Condition_Train_rescaled)\nfakedata = scaler_Train.inverse_transform(generator([tf.random.uniform((10000, 128)), realcondition[:10000]], training=False))\n\nrealhist, realbins = np.histogram(realdata[:10000], bins = 25, range = (10, 600), density=1)\nfakehist, fakebins = np.histogram(fakedata[:,2], bins = 25, range = (10, 600), density=1)\n\nfig, axis = plt.subplots(1, 1, figsize=(8,8))\nplt.title('epoch = '+str(epochs), fontsize=20)\nplt.ylim([0,0.012])\nplt.step(fakebins[:-1], fakehist, label = 'cGAN')\nplt.step(realbins[:-1], realhist, label = 'Pythia8 Signal')\nplt.xlabel('$m_{J_1}$', fontsize=20)\nplt.legend(loc='upper right', fontsize=20)\nfig.savefig('epoch_final.png')\nplt.show()\n\ndef KL_divergent(p,q):\n    return entropy(p,q)\n\nprint(\"KL Divergence D_KL(real||real): {:.3f}\".format(KL_divergent(realhist[:], realhist[:])))\nprint(\"KL Divergence D_KL(fake||real): {:.3f}\".format(KL_divergent(fakehist[:], realhist[:])))\nprint(\"KL Divergence D_KL(flat||real): {:.3f}\".format(KL_divergent(np.full(len(realhist), 1/len(realhist)), realhist[:])))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.469486Z","iopub.status.idle":"2022-05-28T09:52:22.469823Z","shell.execute_reply.started":"2022-05-28T09:52:22.469659Z","shell.execute_reply":"2022-05-28T09:52:22.469675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot loss function & accuracy\n\nplt.figure(figsize=(7,5), dpi=150)\nplt.title('g_loss and d_loss')\nplt.plot(history['g_loss'], label='g_loss')\nplt.plot(history['d_loss'], label='d_loss')\nplt.ylabel('loss function')\nplt.xlabel('epoch')\nplt.legend()\nplt.savefig('loss.png')\nplt.show()\n\nplt.figure(figsize=(7,5), dpi=150)\nplt.title('d_acc')\nplt.plot(history['d_acc'])\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.savefig('accuracy.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.47079Z","iopub.status.idle":"2022-05-28T09:52:22.471159Z","shell.execute_reply.started":"2022-05-28T09:52:22.470972Z","shell.execute_reply":"2022-05-28T09:52:22.470988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot .gif of epochs evolution\n\nsaved_fakedata = np.load('cGAN_saved_fakedata_%d.npz' %(epochs))\n\nprint('files: ', saved_fakedata.files)\nprint('fakedata.shape: ', saved_fakedata['fakedata'].shape)\n\nimages = []\nfor i in range(saved_fakedata['fakedata'].shape[0]):\n    \n    fakedata_old = saved_fakedata['fakedata'][i]\n    fakehist_old, fakebins_old = np.histogram(fakedata_old[:,2], bins = 25, range = (10, 600), density=1)\n    \n    fig, axis = plt.subplots(1, 1, figsize=(8,8), dpi=150)\n    plt.step(fakebins_old[:-1], fakehist_old, label = 'cGAN')\n    plt.step(realbins[:-1], realhist, label = \"Pythia8 Signal\")\n    plt.title('epoch = '+str(i*10000), fontsize=20)\n    plt.ylim([0,0.012])\n    plt.xlabel('$m_{J_1}$', fontsize=20)\n    plt.legend(loc='upper right', fontsize=20)\n    plt.savefig('epoch_'+str(i)+'.png')\n    plt.close()\n\n    images.append(imageio.imread('epoch_'+str(i)+'.png'))\n\nimageio.mimsave('fakedata.gif', images, fps=1.3)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.473038Z","iopub.status.idle":"2022-05-28T09:52:22.473449Z","shell.execute_reply.started":"2022-05-28T09:52:22.473266Z","shell.execute_reply":"2022-05-28T09:52:22.473284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load test data\n\npath_test_data = '../input/phys591000-2022-final-project-iii/test_sample_for_discriminator.npz'\ntest_data = np.load(path_test_data)\n\nprint('test_data.files: ', test_data.files)\nprint('test_sample.shape: ', test_data['test_sample'].shape)\n\ntest = pd.DataFrame(test_data['test_sample'])\ntest.columns = ['pxj1', 'pyj1', 'pzj1', 'mj1', 'pxj2', 'pyj2', 'pzj2', 'mj2']\n\npd.reset_option('display')\nprint('test')\ndisplay(test)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.474528Z","iopub.status.idle":"2022-05-28T09:52:22.474889Z","shell.execute_reply.started":"2022-05-28T09:52:22.474711Z","shell.execute_reply":"2022-05-28T09:52:22.474728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data processing: test data → testing features + conditional label\n\ntest_pj1 = np.sqrt(test['pxj1']**2 + test['pyj1']**2 + test['pzj1']**2)\ntest_pTj1 = np.sqrt(test['pxj1']**2 + test['pyj1']**2)\ntest_phij1 = np.arccos(test['pxj1']/test_pTj1)\ntest_etaj1 = np.arcsinh(test['pzj1']/test_pTj1)\ntest_mj1 = test['mj1']\ntest_E1 = np.sqrt(test_pj1**2 + test_mj1**2)\n\ntest_pj2 = np.sqrt(test['pxj2']**2 + test['pyj2']**2 + test['pzj2']**2)\ntest_pTj2 = np.sqrt(test['pxj2']**2 + test['pyj2']**2)\ntest_phij2 = np.arccos(test['pxj2']/test_pTj2)\ntest_j2_rotate = test_phij2 - test_phij1\ntest_etaj2 = np.arcsinh(test['pzj2']/test_pTj2)\ntest_mj2 = test['mj2']\ntest_E2 = np.sqrt(test_pj2**2 + test_mj2**2)\n\ntest_mjj = np.sqrt((test_E1+test_E2)**2 - ((test['pxj1']+test['pxj2'])**2 + (test['pyj1']+test['pyj2'])**2 + (test['pzj1']+test['pzj2'])**2))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.476104Z","iopub.status.idle":"2022-05-28T09:52:22.477282Z","shell.execute_reply.started":"2022-05-28T09:52:22.476867Z","shell.execute_reply":"2022-05-28T09:52:22.476911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collect 7 testing features\n\ntest_fit = pd.DataFrame({'pTj1': test_pTj1,\n                         'etaj1': test_etaj1,\n                         'mj1': test_mj1,\n                         'pTj2': test_pTj2,\n                         'phij2': test_j2_rotate,\n                         'etaj2': test_etaj2,\n                         'mj2': test_mj2})\n\npd.reset_option('display')\nprint('test_fit')\ndisplay(test_fit)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.478981Z","iopub.status.idle":"2022-05-28T09:52:22.479578Z","shell.execute_reply.started":"2022-05-28T09:52:22.479309Z","shell.execute_reply":"2022-05-28T09:52:22.479338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rescale testing features to [-1,1]\n\nTest = test_fit.values\nscaler_Test = MinMaxScaler((-1, 1))\nscaler_Test.fit(Test)\nTest_rescaled = scaler_Test.transform(Test)\n\nprint('Test_rescaled.shape:', Test_rescaled.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.481165Z","iopub.status.idle":"2022-05-28T09:52:22.481689Z","shell.execute_reply.started":"2022-05-28T09:52:22.481432Z","shell.execute_reply":"2022-05-28T09:52:22.481458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collect 1 testing conditional label\n\ncondition_Test = pd.DataFrame({'mjj': test_mjj})\n\npd.reset_option('display')\nprint('condition_Test')\ndisplay(condition_Test)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.483548Z","iopub.status.idle":"2022-05-28T09:52:22.484094Z","shell.execute_reply.started":"2022-05-28T09:52:22.483814Z","shell.execute_reply":"2022-05-28T09:52:22.483841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rescale testing conditional label to [0,1]\n\nCondition_Test = condition_Test.values\nscaler_Condition_Test = MinMaxScaler((0, 1))\nscaler_Condition_Test.fit(Condition_Test)\nCondition_Test_rescaled = scaler_Condition_Test.transform(Condition_Test)\n\nprint('Condition_Test_rescaled.shape:', Condition_Test_rescaled.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.4873Z","iopub.status.idle":"2022-05-28T09:52:22.488491Z","shell.execute_reply.started":"2022-05-28T09:52:22.488164Z","shell.execute_reply":"2022-05-28T09:52:22.488197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict test data → result\n\nresult = discriminator.predict([Test_rescaled, Condition_Test_rescaled])\nprint('result.shape:', result.shape)\n\nprint('max of result:', np.max(result))\nprint('median of result:', np.median(result))\nprint('min of result:', np.min(result))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.489845Z","iopub.status.idle":"2022-05-28T09:52:22.490402Z","shell.execute_reply.started":"2022-05-28T09:52:22.490116Z","shell.execute_reply":"2022-05-28T09:52:22.490159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rescale result to [0,1]\n\nscaler_result = MinMaxScaler((0, 1))\nscaler_result.fit(result)\nresult_rescaled = scaler_result.transform(result)\n\nprint('result_rescaled.shape:', result_rescaled.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.49233Z","iopub.status.idle":"2022-05-28T09:52:22.492883Z","shell.execute_reply.started":"2022-05-28T09:52:22.492599Z","shell.execute_reply":"2022-05-28T09:52:22.492626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distribution of rescaled result\n\nresult_rescaled_hist, result_rescaled_bins = np.histogram(result_rescaled, bins = 40, range = (0, 1), density=1)\n\nfig, axis = plt.subplots(1, 1, figsize=(8,8))\nplt.step(result_rescaled_bins[:-1], result_rescaled_hist, label = \"Prediction\")\nplt.show()\n\nprint(np.max(result_rescaled))\nprint(np.median(result_rescaled))\nprint(np.min(result_rescaled))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.495Z","iopub.status.idle":"2022-05-28T09:52:22.495545Z","shell.execute_reply.started":"2022-05-28T09:52:22.495291Z","shell.execute_reply":"2022-05-28T09:52:22.495316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load submission template\n\nsubmission_template = pd.read_csv('../input/phys591000-2022-final-project-iii/submission_template_randomguess.csv')\n\npd.reset_option('display')\nprint('submission_template')\ndisplay(submission_template)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.496855Z","iopub.status.idle":"2022-05-28T09:52:22.49741Z","shell.execute_reply.started":"2022-05-28T09:52:22.497122Z","shell.execute_reply":"2022-05-28T09:52:22.497174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save submission prediciton\n\nsubmission = submission_template.copy()\n\nsplit_level = np.median(result_rescaled)\nfor i in range(result_rescaled.shape[0]):\n    if result_rescaled[i] <= split_level:\n        final_label = 0\n    else:\n        final_label = 1\n    submission['prediction'][i] = final_label\n    \npd.reset_option('display')\nprint('submission')\ndisplay(submission)\n\nsubmission.to_csv('submission.csv', index=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.499082Z","iopub.status.idle":"2022-05-28T09:52:22.499505Z","shell.execute_reply.started":"2022-05-28T09:52:22.499333Z","shell.execute_reply":"2022-05-28T09:52:22.499351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check submission prediciton\n\ncount = 0\nfor i in submission['prediction']:\n    if i == 1:\n        count += 1\n        \nprint('predict to real:', count)\nprint('predict to fake:', result_rescaled.shape[0] - count)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:52:22.500517Z","iopub.status.idle":"2022-05-28T09:52:22.500843Z","shell.execute_reply.started":"2022-05-28T09:52:22.500681Z","shell.execute_reply":"2022-05-28T09:52:22.500698Z"},"trusted":true},"execution_count":null,"outputs":[]}]}